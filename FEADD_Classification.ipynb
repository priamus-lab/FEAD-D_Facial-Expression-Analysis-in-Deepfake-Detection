{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "k2QAjaBWKRsn",
        "Iton5L4lDofb",
        "OMLeByKcDvCS",
        "Sypx24DHD4GG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FEAD-D: Facial Expression Analysis in Deepfake Detection\n",
        "---\n",
        "Michela Gravina, Antonio Galli, Geremia De Micco, Stefano Marrone, Giuseppe Fiameni, Carlo Sansone\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Before running the code, please:\n",
        "\n",
        "*  Change the runtime setting by selecting the GPU as the accelerator.\n",
        "*  (Optional) Connect the notebook to your Drive\n",
        "*  Download the weights of the models at this link: https://drive.google.com/drive/folders/1jeoqIl6SH5eRZooVesM2gqtBuTxOJbiU?usp=sharing\n"
      ],
      "metadata": {
        "id": "0C9JFP9__Yx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "k2QAjaBWKRsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5"
      ],
      "metadata": {
        "id": "1mlZop-QHtbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import math\n",
        "from keras.models import load_model,model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from random import randint\n",
        "from random import sample\n",
        "import random\n",
        "import dlib\n",
        "import pickle5 as pickle\n",
        "from keras.layers import Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.layers import LSTM, GRU, Bidirectional\n",
        "from keras.layers import Activation\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "import time\n",
        "\n",
        "print(sys.version)\n",
        "np.version.version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "BQ2IQh4f_bHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "4DsAw5GFZGB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Definition\n",
        "\n",
        "The implemented framework consists of the following modules:\n",
        "\n",
        "* **Face detection**, in which the target video is analyzed to detect one or more faces.\n",
        "* **Features Extraction**, that analyzes the texture of target images and extracts the emotion from the detected face frame by frame.\n",
        "* **Features temporal analysis**, in which all the features extracted in the previous stages are analyzed together in a cross-frame fashion to spot incoherent and unnatural patterns in the emotional evolution of the target subject.\n"
      ],
      "metadata": {
        "id": "vQSc4BH5_3UI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Face detection"
      ],
      "metadata": {
        "id": "Iton5L4lDofb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def increseContrast(frame):\n",
        "    lab= cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "\n",
        "    limg = cv2.merge((cl,a,b))\n",
        "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    final_frame = cv2.hconcat((frame, final)) # or vconcat for vertical concatenation\n",
        "\n",
        "    return final\n",
        "\n",
        "\n",
        "def increaseBrightnessBrg(img, value=30):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "\n",
        "    lim = 255 - value\n",
        "    v[v > lim] = 255\n",
        "    v[v <= lim] += value\n",
        "\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img\n",
        "\n",
        "def automaticBrightnessContrastBrg(image, clip_hist_percent=25):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Calculate grayscale histogram\n",
        "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
        "    hist_size = len(hist)\n",
        "    # Calculate cumulative distribution from the histogram\n",
        "    accumulator = []\n",
        "    accumulator.append(float(hist[0]))\n",
        "    for index in range(1, hist_size):\n",
        "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
        "    # Locate points to clip\n",
        "    maximum = accumulator[-1]\n",
        "    clip_hist_percent *= (maximum/100.0)\n",
        "    clip_hist_percent /= 2.0\n",
        "    # Locate left cut\n",
        "    minimum_gray = 0\n",
        "    while accumulator[minimum_gray] < clip_hist_percent:\n",
        "        minimum_gray += 1\n",
        "    # Locate right cut\n",
        "    maximum_gray = hist_size -1\n",
        "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
        "        maximum_gray -= 1\n",
        "    # Calculate alpha and beta values\n",
        "    alpha = 1\n",
        "    try:\n",
        "        alpha = 255 / (maximum_gray - minimum_gray)\n",
        "    except ZeroDivisionError:\n",
        "        pass\n",
        "\n",
        "    beta = -minimum_gray * alpha\n",
        "\n",
        "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    splitImgs = cv2.hconcat((frame, auto_result)) # or vconcat for vertical concatenation\n",
        "    return auto_result\n",
        "\n",
        "\n",
        "# Crop\n",
        "def crop(img, x, y, w, h, margin):\n",
        "    x -= margin\n",
        "    y -= margin\n",
        "    w += margin * 2\n",
        "    h += margin * 2\n",
        "    if x < 0:\n",
        "        x = 0\n",
        "    if y <= 0:\n",
        "        y = 0\n",
        "    return img[y:y + h, x:x + w]\n",
        "\n",
        "def sqareMarginBBOX(top, bottom, left, right, fromInterpolation):\n",
        "    global frame_FSHS\n",
        "    global frameToCut\n",
        "    if fromInterpolation == True:\n",
        "        h, w, c = frameToCut.shape\n",
        "    else:\n",
        "        h, w, c = frame_FSHS.shape\n",
        "    minLeft = 0\n",
        "    minTop = 0\n",
        "    maxBottom = h\n",
        "    maxRight = w\n",
        "    maxDim = max((bottom - top), (right - left))\n",
        "    margin = maxDim * 0.5\n",
        "\n",
        "    newTop = int(top - margin)\n",
        "    offSetTop = 0\n",
        "    if newTop < 0:\n",
        "        offSetTop = math.ceil(abs(newTop))\n",
        "        newTop = 0\n",
        "\n",
        "    newBottom = int(top + maxDim + margin + offSetTop)\n",
        "    if newBottom > maxBottom:\n",
        "        offSetBottom = math.ceil(abs(newBottom - maxBottom))\n",
        "        newBottom = maxBottom\n",
        "        newTop = newTop - offSetBottom\n",
        "\n",
        "    newLeft = int(left - margin)\n",
        "    offSetLeft = 0\n",
        "    if newLeft < 0:\n",
        "        offSetLeft = math.ceil(abs(newLeft))\n",
        "        newLeft = 0\n",
        "\n",
        "    newRight = int(left + maxDim + margin + offSetLeft)\n",
        "    if newRight > maxRight:\n",
        "        offSetRight = math.ceil(abs(newRight - maxRight))\n",
        "        newRight = maxRight\n",
        "        newLeft = newLeft - offSetRight\n",
        "    box = int(newTop), int(newRight), int(newBottom), int(newLeft)\n",
        "    return box\n",
        "\n",
        "def cropBBox(box, fromInterpolation):\n",
        "    newTop, newRight, newBottom, newLeft = box\n",
        "    newTop = int(newTop)\n",
        "    newRight = int(newRight)\n",
        "    newBottom = int(newBottom)\n",
        "    newLeft = int(newLeft)\n",
        "    if newTop < 0:\n",
        "        newTop = 0\n",
        "        newRight = int(newRight)\n",
        "        newBottom = int(newBottom)\n",
        "        newLeft = int(newLeft)\n",
        "    if newLeft < 0:\n",
        "        newLeft = 0\n",
        "    if abs(newBottom - newTop) != squareDim_noZoom:\n",
        "        newBottom = newTop + squareDim_noZoom\n",
        "    if abs(newRight - newLeft) != squareDim_noZoom:\n",
        "        newRight = newLeft + squareDim_noZoom\n",
        "\n",
        "    if abs(newBottom - newTop) != abs(newRight - newLeft):\n",
        "        z = 0\n",
        "    if fromInterpolation == True:\n",
        "        faceInFrame = frameToCut[newTop:newBottom,newLeft:newRight]  # crop frame_FSHS ************************************************\n",
        "    else:\n",
        "        faceInFrame = frame_FSHS[newTop:newBottom, newLeft:newRight]  # crop frame_FSHS ************************************************\n",
        "    return faceInFrame\n",
        "\n",
        "def resizeAndAppend():\n",
        "    global facesDetected\n",
        "    global frames_48\n",
        "    global frames_299\n",
        "    global frames_380_B3_convLSTM\n",
        "    global frame_id\n",
        "    global last_detected_face_48\n",
        "    global last_detected_face_299\n",
        "    global back_interp_frame_index\n",
        "    global middle_interp_frame_index\n",
        "    global foreward_interp_frame_index\n",
        "    global count\n",
        "    global index_detected\n",
        "    global bbox_last_detected_faces\n",
        "    global first_frame\n",
        "    global last_BBox\n",
        "    global squareDim_noZoom\n",
        "    global first_frame_BBox\n",
        "\n",
        "    facesDetected = facesDetected + 1\n",
        "\n",
        "    moreConfidenceFace = 0\n",
        "    max_conf_score = 0\n",
        "    max_distance_from_choosedFace = 1000\n",
        "    if len(detected_faces_raw)>1:\n",
        "        for i in range(len(detected_faces_raw)):\n",
        "            if first_frame:\n",
        "                if detected_faces_raw[i].confidence > max_conf_score:\n",
        "                    max_conf_score = detected_faces_raw[i].confidence\n",
        "                    moreConfidenceFace = i\n",
        "            else:\n",
        "                (t1, r1, b1, l1) = first_frame_BBox\n",
        "                l2 = detected_faces_raw[i].rect.left()\n",
        "                t2 = detected_faces_raw[i].rect.top()\n",
        "                r2 = detected_faces_raw[i].rect.right()\n",
        "                b2 = detected_faces_raw[i].rect.bottom()\n",
        "                (xc1, yc1) = (l1 + r1 / 2, t1 + b1 / 2)\n",
        "                (xc2, yc2) = (l2 + r2 / 2, t2 + b2 / 2)\n",
        "\n",
        "                if abs(xc1-xc2) < max_distance_from_choosedFace:\n",
        "                    max_distance_from_choosedFace = abs(xc1-xc2)\n",
        "                    moreConfidenceFace = i\n",
        "\n",
        "\n",
        "    #top, right, bottom, left = detected_faces_raw[0]\n",
        "    left = detected_faces_raw[moreConfidenceFace].rect.left()\n",
        "    top = detected_faces_raw[moreConfidenceFace].rect.top()\n",
        "    right = detected_faces_raw[moreConfidenceFace].rect.right()\n",
        "    bottom = detected_faces_raw[moreConfidenceFace].rect.bottom()\n",
        "    if left<0:\n",
        "        left=0\n",
        "    if top<=0:\n",
        "        top=0\n",
        "    #box = top, right, bottom, left\n",
        "    index_detected.append(count)\n",
        "\n",
        "    curret_sqaured_box = sqareMarginBBOX(top, bottom, left, right, False)\n",
        "\n",
        "    if first_frame:\n",
        "        first_frame = False\n",
        "        last_BBox = curret_sqaured_box\n",
        "        top, right, bottom, left = curret_sqaured_box\n",
        "        squareDim_noZoom = max(abs(bottom - top),abs(right - left))\n",
        "        first_frame_BBox = curret_sqaured_box\n",
        "\n",
        "    else:\n",
        "        (t1, r1, b1, l1) = last_BBox\n",
        "        (t2, r2, b2, l2) = curret_sqaured_box\n",
        "        dim_1 = max(abs(b1-t1),abs(r1-l1))\n",
        "        dim_2 = max(abs(b2-t2),abs(r2-l2))\n",
        "        (xc1, yc1) = (l1 + r1 / 2, t1 + b1 / 2)\n",
        "        (xc2, yc2) = (l2 + r2 / 2, t2 + b2 / 2)\n",
        "\n",
        "        dx_up = False\n",
        "        dx_down = False\n",
        "        sx_up = False\n",
        "        sx_down = False\n",
        "        if xc2 >= xc1:\n",
        "            if yc2 >= yc1:\n",
        "                dx_up = True\n",
        "            else:\n",
        "                dx_down = True\n",
        "        else:\n",
        "            if yc2 >= yc1:\n",
        "                sx_up = True\n",
        "            else:\n",
        "                sx_down = True\n",
        "        alpha = 0.1\n",
        "        delta_x = float(abs(xc2 - xc1))*alpha\n",
        "        delta_y = float(abs(yc2 - yc1))*alpha\n",
        "        if dx_up == True:\n",
        "            newbbox = (float(t1) + delta_y , float(l1) + delta_x + squareDim_noZoom , float(t1) + delta_y + squareDim_noZoom, float(l1) + delta_x)\n",
        "        else:\n",
        "            if dx_down == True:\n",
        "                newbbox = (float(t1) - delta_y , float(l1) + delta_x  + squareDim_noZoom , float(t1) - delta_y + squareDim_noZoom, float(l1) + delta_x)\n",
        "            else:\n",
        "                if sx_up == True:\n",
        "                    newbbox = (float(t1) + delta_y , float(l1) - delta_x  + squareDim_noZoom, float(t1) + delta_y + squareDim_noZoom, float(l1) - delta_x)\n",
        "                else:\n",
        "                    if sx_down == True:\n",
        "                        newbbox = (float(t1) - delta_y , float(l1) - delta_x  + squareDim_noZoom, float(t1) - delta_y + squareDim_noZoom, float(l1) - delta_x)\n",
        "        last_BBox = newbbox\n",
        "\n",
        "\n",
        "    bbox_last_detected_faces.append(last_BBox)\n",
        "    faceInFrame = cropBBox(last_BBox, False)\n",
        "\n",
        "    frames_380_B3_convLSTM.append(faceInFrame)\n",
        "\n",
        "    frame_48_gray = cv2.cvtColor(faceInFrame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_299_rgb = cv2.cvtColor(faceInFrame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    resizedFrame_48 = cv2.resize(frame_48_gray, (48, 48),\n",
        "                                interpolation=cv2.INTER_LINEAR)\n",
        "    resizedFrame_299 = cv2.resize(frame_299_rgb, (299, 299),\n",
        "                                interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    last_detected_face_48 = resizedFrame_48\n",
        "    last_detected_face_299 = resizedFrame_299\n",
        "\n",
        "    faceRGB = cv2.cvtColor(faceInFrame, cv2.COLOR_BGR2RGB)\n",
        "    face_380_rgb = cv2.resize(faceRGB, (380, 380), interpolation=cv2.INTER_LINEAR)\n",
        "    frames_48.append(resizedFrame_48)\n",
        "    frames_299.append(resizedFrame_299)\n",
        "    frame_id.append(count)\n",
        "\n",
        "\n",
        "# Interpolation methods\n",
        "def checkInterpolationAndResize():\n",
        "    resizeAndAppend()\n",
        "    global frames_48\n",
        "    global frames_299\n",
        "    global frame_id\n",
        "    global facesInterpolated\n",
        "    global count\n",
        "    global back_interp_frame_index\n",
        "    global middle_interp_frame_index\n",
        "    global index_detected\n",
        "    global frames_back_interp\n",
        "    global frames_middle_interp\n",
        "    global frames_forward_interp\n",
        "\n",
        "    if len(back_interp_frame_index) > 0:\n",
        "        (t1, r1, b1, l1) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 1]\n",
        "        (t2, r2, b2, l2) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 2]\n",
        "\n",
        "        dim_1 = max(abs(b1-t1),abs(r1-l1))\n",
        "        dim_2 = max(abs(b2-t2),abs(r2-l2))\n",
        "\n",
        "        (xc1, yc1) = (l1 + r1 / 2, t1 + b1 / 2)\n",
        "        (xc2, yc2) = (l2 + r2 / 2, t2 + b2 / 2)\n",
        "        dx_up = False\n",
        "        dx_down = False\n",
        "        sx_up = False\n",
        "        sx_down = False\n",
        "        if xc2 >= xc1:\n",
        "            if yc2 >= yc1:\n",
        "                dx_up = True\n",
        "            else:\n",
        "                dx_down = True\n",
        "        else:\n",
        "            if yc2 >= yc1:\n",
        "                sx_up = True\n",
        "            else:\n",
        "                sx_down = True\n",
        "        index_diff = index_detected[len(index_detected) - 1] - index_detected[len(index_detected) - 2]\n",
        "        delta_x = 1\n",
        "        try:\n",
        "            delta_x = float(abs(xc2 - xc1)) / float(index_diff)\n",
        "        except ZeroDivisionError:\n",
        "            pass\n",
        "\n",
        "        delta_y = 1\n",
        "        try:\n",
        "            delta_y = float(abs(yc2 - yc1)) / float(index_diff)\n",
        "        except ZeroDivisionError:\n",
        "            pass\n",
        "\n",
        "        num_box_to_create = len(back_interp_frame_index)\n",
        "        for i in range(num_box_to_create):\n",
        "            if dx_up == True:\n",
        "                temp_top = float(t1) - delta_y *(i + 1)\n",
        "                temp_left = float(l1) - delta_x * (i + 1)\n",
        "                temp_bottom = temp_top + squareDim_noZoom\n",
        "                temp_right = temp_left + squareDim_noZoom\n",
        "                newbbox = (temp_top,temp_right,temp_bottom,temp_left)\n",
        "                resizeAppendIinterpolatedFrames(newbbox, True, False, False, i)\n",
        "            else:\n",
        "                if dx_down == True:\n",
        "                    temp_top = float(t1) + delta_y *i\n",
        "                    temp_left = float(l1) - delta_x * i\n",
        "                    temp_bottom = temp_top + squareDim_noZoom\n",
        "                    temp_right = temp_left + squareDim_noZoom\n",
        "                    newbbox = (temp_top,temp_right,temp_bottom,temp_left)\n",
        "                    resizeAppendIinterpolatedFrames(newbbox, True, False, False, i)\n",
        "                else:\n",
        "                    if sx_up == True:\n",
        "                        temp_top = float(t1) - delta_y *i\n",
        "                        temp_left = float(l1) + delta_x * i\n",
        "                        temp_bottom = temp_top + squareDim_noZoom\n",
        "                        temp_right = temp_left + squareDim_noZoom\n",
        "                        newbbox = (temp_top,temp_right,temp_bottom,temp_left)\n",
        "                        resizeAppendIinterpolatedFrames(newbbox, True, False, False, i)\n",
        "                    else:\n",
        "                        if sx_down == True:\n",
        "                            temp_top = float(t1) + delta_y *i\n",
        "                            temp_left = float(l1) + delta_x * i\n",
        "                            temp_bottom = temp_top + squareDim_noZoom\n",
        "                            temp_right = temp_left + squareDim_noZoom\n",
        "                            newbbox = (temp_top,temp_right,temp_bottom,temp_left)\n",
        "                            resizeAppendIinterpolatedFrames(newbbox, True, False, False, i)\n",
        "        frames_back_interp = []\n",
        "        back_interp_frame_index = []\n",
        "\n",
        "    if len(middle_interp_frame_index) > 0:\n",
        "        (t1, r1, b1, l1) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 1]\n",
        "        (t2, r2, b2, l2) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 2]\n",
        "        dim_1 = max(abs(b1-t1),abs(r1-l1))\n",
        "        dim_2 = max(abs(b2-t2),abs(r2-l2))\n",
        "\n",
        "        (xc1, yc1) = (l1 + r1 / 2, t1 + b1 / 2)\n",
        "        (xc2, yc2) = (l2 + r2 / 2, t2 + b2 / 2)\n",
        "        dx_up = False\n",
        "        dx_down = False\n",
        "        sx_up = False\n",
        "        sx_down = False\n",
        "        if xc2 >= xc1:\n",
        "            if yc2 >= yc1:\n",
        "                dx_up = True\n",
        "            else:\n",
        "                dx_down = True\n",
        "        else:\n",
        "            if yc2 >= yc1:\n",
        "                sx_up = True\n",
        "            else:\n",
        "                sx_down = True\n",
        "        num_box_to_create = len(middle_interp_frame_index)\n",
        "        delta_x = float(abs(xc2 - xc1)) / float(num_box_to_create + 1)\n",
        "        delta_y = float(abs(yc2 - yc1)) / float(num_box_to_create + 1)\n",
        "        for i in range(num_box_to_create):\n",
        "            if dx_up == True:\n",
        "                newbbox = (float(t1) + delta_y , float(l1) + delta_x + squareDim_noZoom , float(t1) + delta_y + squareDim_noZoom, float(l1) + delta_x)  # sommo o sottraggo il delta a seconda del movimento\n",
        "                resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "            else:\n",
        "                if dx_down == True:\n",
        "                    newbbox = (float(t1) - delta_y , float(l1) + delta_x  + squareDim_noZoom , float(t1) - delta_y + squareDim_noZoom, float(l1) + delta_x)\n",
        "                    resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "                else:\n",
        "                    if sx_up == True:\n",
        "                        newbbox = (float(t1) + delta_y , float(l1) - delta_x  + squareDim_noZoom, float(t1) + delta_y + squareDim_noZoom, float(l1) - delta_x)\n",
        "                        resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "                    else:\n",
        "                        if sx_down == True:\n",
        "                            newbbox = (float(t1) - delta_y , float(l1) - delta_x  + squareDim_noZoom, float(t1) - delta_y + squareDim_noZoom, float(l1) - delta_x)\n",
        "                            resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "        frames_middle_interp = []\n",
        "        middle_interp_frame_index = []\n",
        "\n",
        "def forwardInterpolation():\n",
        "    global forward_interp_frame_index\n",
        "    global frames_forward_interp\n",
        "    forward_interp_frame_index = middle_interp_frame_index\n",
        "    frames_forward_interp = frames_middle_interp\n",
        "\n",
        "    (t1, r1, b1, l1) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 1]\n",
        "    (t2, r2, b2, l2) = bbox_last_detected_faces[len(bbox_last_detected_faces) - 2]\n",
        "\n",
        "    dim_1 = max(abs(b1-t1),abs(r1-l1))\n",
        "    dim_2 = max(abs(b2-t2),abs(r2-l2))\n",
        "\n",
        "    (xc1, yc1) = (l1 + r1 / 2, t1 + b1 / 2)\n",
        "    (xc2, yc2) = (l2 + r2 / 2, t2 + b2 / 2)\n",
        "\n",
        "    dx_up = False\n",
        "    dx_down = False\n",
        "    sx_up = False\n",
        "    sx_down = False\n",
        "    if xc2 >= xc1:\n",
        "\n",
        "        if yc2 >= yc1:\n",
        "            dx_up = True\n",
        "        else:\n",
        "            dx_down = True\n",
        "    else:\n",
        "        if yc2 >= yc1:\n",
        "            sx_up = True\n",
        "        else:\n",
        "            sx_down = True\n",
        "\n",
        "    index_diff = index_detected[len(index_detected) - 1] - index_detected[len(index_detected) - 2]\n",
        "    delta_x = 1\n",
        "    try:\n",
        "        delta_x = float(abs(xc2 - xc1)) / float(index_diff)\n",
        "    except ZeroDivisionError:\n",
        "        pass\n",
        "\n",
        "    delta_y = 1\n",
        "    try:\n",
        "        delta_y = float(abs(yc2 - yc1)) / float(index_diff)\n",
        "    except ZeroDivisionError:\n",
        "        pass\n",
        "\n",
        "    num_box_to_create = len(forward_interp_frame_index)\n",
        "\n",
        "    for i in range(num_box_to_create):\n",
        "        if dx_up == True:\n",
        "                newbbox = (float(t2) + delta_y , float(l2) + delta_x + squareDim_noZoom , float(t2) + delta_y + squareDim_noZoom, float(l2) + delta_x)\n",
        "                resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "        else:\n",
        "            if dx_down == True:\n",
        "                newbbox = (float(t2) - delta_y , float(l2) + delta_x  + squareDim_noZoom , float(t2) - delta_y + squareDim_noZoom, float(l2) + delta_x)\n",
        "                resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "            else:\n",
        "                if sx_up == True:\n",
        "                    newbbox = (float(t2) + delta_y , float(l2) - delta_x  + squareDim_noZoom, float(t2) + delta_y + squareDim_noZoom, float(l2) - delta_x)\n",
        "                    resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "                else:\n",
        "                    if sx_down == True:\n",
        "                        newbbox = (float(t2) - delta_y , float(l2) - delta_x  + squareDim_noZoom, float(t2) - delta_y + squareDim_noZoom, float(l2) - delta_x)\n",
        "                        resizeAppendIinterpolatedFrames(newbbox, False, True, False, i)\n",
        "    frames_forward_interp = []\n",
        "    forward_interp_frame_index = []\n",
        "\n",
        "def resizeAppendIinterpolatedFrames(newbbox, back, middle, forw, index):\n",
        "    global frames_middle_interp\n",
        "    global frames_48\n",
        "    global frames_299\n",
        "    global frame_id\n",
        "    global facesInterpolated\n",
        "    global frameToCut\n",
        "\n",
        "    top, right, bottom, left = newbbox\n",
        "    if middle == True:\n",
        "        frameToCut = frames_middle_interp[index]\n",
        "    else:\n",
        "        if back == True:\n",
        "            frameToCut = frames_back_interp[index]\n",
        "        else:\n",
        "            if forw == True:\n",
        "                frameToCut = frames_forward_interp[index]\n",
        "\n",
        "    temp_bbox = int(top), int(right), int(bottom), int(left),\n",
        "    face_interp = cropBBox(temp_bbox, True)\n",
        "    if face_interp.size == 0:\n",
        "        print('empty list')\n",
        "    else:\n",
        "        frames_380_B3_convLSTM.append(face_interp)\n",
        "\n",
        "        frame_48_gray = cv2.cvtColor(face_interp, cv2.COLOR_BGR2GRAY)\n",
        "        frame_299_rgb = cv2.cvtColor(face_interp, cv2.COLOR_BGR2RGB)\n",
        "        resizedFrame_48 = cv2.resize(frame_48_gray, (48, 48),\n",
        "                                    interpolation=cv2.INTER_LINEAR)\n",
        "        resizedFrame_299 = cv2.resize(frame_299_rgb, (299, 299),\n",
        "                                    interpolation=cv2.INTER_LINEAR)\n",
        "        faceRGB = cv2.cvtColor(face_interp, cv2.COLOR_BGR2RGB)\n",
        "        face_380_rgb = cv2.resize(faceRGB, (380, 380), interpolation=cv2.INTER_LINEAR)\n",
        "        frames_48.append(resizedFrame_48)\n",
        "        frames_299.append(resizedFrame_299)\n",
        "\n",
        "\n",
        "        if middle == True:\n",
        "            frame_id.append(middle_interp_frame_index[index])\n",
        "        else:\n",
        "            if back == True:\n",
        "                frame_id.append(back_interp_frame_index[index])\n",
        "            else:\n",
        "                if forw == True:\n",
        "                    frame_id.append(forward_interp_frame_index[index])\n",
        "        facesInterpolated = facesInterpolated + 1\n",
        "\n",
        "\n",
        "# Utils\n",
        "\n",
        "def createVideoFile(frame_rate, size, channels, array,videoPathName):\n",
        "    fourcc_mp4 = cv2.VideoWriter_fourcc(*'MP4V') #cv2.VideoWriter_fourcc(*'DIVX')\n",
        "    size = size\n",
        "    videoOut = cv2.VideoWriter(f'{videoPathName}.mp4',fourcc_mp4, frame_rate, size, channels)\n",
        "    for i in range(len(array)):\n",
        "        img = array[i].astype('uint8')\n",
        "        videoOut.write(img)\n",
        "        videoOut.release()\n",
        "\n",
        "\n",
        "\n",
        "def name_frame_num_Video(vid):\n",
        "    cap = cv2.VideoCapture(vid)\n",
        "    frame_num = cap.get(7)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    cap.release()\n",
        "    nameVideo = vid.rsplit(\"/\")[-1]\n",
        "    print(f'video {nameVideo}, frame_num {frame_num}, fps {fps}')\n",
        "    return nameVideo, frame_num, fps"
      ],
      "metadata": {
        "id": "UWjNuiNG_wh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2: Features Extraction"
      ],
      "metadata": {
        "id": "OMLeByKcDvCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features_extraction_step2(x_data_48, x_data_299, fer67_cnn, incV3_cnn ):\n",
        "  x_data_48 = np.expand_dims(x_data_48, axis=-1)\n",
        "  predictions2048_48 = fer67_cnn.predict(x_data_48, batch_size = 16)\n",
        "\n",
        "  columns_Fer67_2048 =[('f_Fer' + str(i)) for i in range(2048)] #f1,f2,f3....fn\n",
        "  df_fer67_2048Features = pd.DataFrame(predictions2048_48,columns = columns_Fer67_2048)\n",
        "  df_fer67_2048Features['frame_id'] = np.arange(df_fer67_2048Features.shape[0]).tolist()\n",
        "  df_fer67_2048Features = df_fer67_2048Features.set_index('frame_id')\n",
        "\n",
        "  x_data_preproc_299 = keras.applications.inception_v3.preprocess_input(x_data_299)\n",
        "  predictions_299 = incV3_cnn.predict(x_data_preproc_299, batch_size = 16)\n",
        "  columns_InceptionV3 =[('f_Inc' + str(i)) for i in range(2048)] #f1,f2,f3....fn\n",
        "  df_incV3_2048Features = pd.DataFrame(predictions_299,columns = columns_InceptionV3)\n",
        "  df_incV3_2048Features['frame_id'] = np.arange(df_incV3_2048Features.shape[0]).tolist()\n",
        "  df_incV3_2048Features = df_incV3_2048Features.set_index('frame_id')\n",
        "  merged_df_fer67_IncV3 = pd.merge(df_fer67_2048Features, df_incV3_2048Features, left_index=True, right_index=True, how='inner',validate=\"one_to_one\")\n",
        "  return merged_df_fer67_IncV3\n",
        "\n",
        "def importModels(dataMainDirectory):\n",
        "    print('LOADING MODELS...')\n",
        "    print('------------------------------------ LOADING fer67AccMicroExpreDetector')\n",
        "    json_file = open(f'{dataMainDirectory}fer67AccMicroExpreDetector.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(f'{dataMainDirectory}fer67AccMicroExpreDetector.h5')\n",
        "    from keras.models import Sequential\n",
        "    fer67_cnn = Sequential()\n",
        "    for layer in loaded_model.layers[:-7]: # just exclude last layer from copying\n",
        "        fer67_cnn.add(layer)\n",
        "\n",
        "    print('------------------------------------ LOADING InceptV3')\n",
        "\n",
        "    incV3_cnn = InceptionV3(include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling='max',\n",
        "    )\n",
        "\n",
        "    return fer67_cnn, incV3_cnn"
      ],
      "metadata": {
        "id": "Qw8aob26ES8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Features temporal analysis"
      ],
      "metadata": {
        "id": "Sypx24DHD4GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_model_fc(base_path):\n",
        "  time_steps = 300\n",
        "  features = 4096\n",
        "  model = Sequential()\n",
        "  model.add(Bidirectional(LSTM(units = 1024,return_sequences=True)))\n",
        "  model.add(Bidirectional(LSTM(units = 512, return_sequences=True)))\n",
        "  model.add(Bidirectional(LSTM(units = 512, return_sequences=False)))\n",
        "  model.add(Dense(512, activation = 'relu'))\n",
        "  model.add(Dense(256, activation = 'relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.build((None, time_steps, features ))\n",
        "  model.summary()\n",
        "  model.load_weights(base_path + 'model_weights.h5')\n",
        "  return model"
      ],
      "metadata": {
        "id": "HH2F5YFrEQd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction\n",
        "\n",
        "\n",
        "\n",
        "**dataMainDirectory** is the path to the folder containing the model weights:\n",
        "\n",
        "\n",
        "*   fer67AccMicroExpreDetector.h5 / fer67AccMicroExpreDetector.json\n",
        "*   mmod_human_face_detector.dat\n",
        "*   model_weights.h5\n",
        "\n",
        "**path_name** is the path to the folder containing the videos to classify\n",
        "\n",
        "Please update the dataMainDirectory and path_name variables according to the location where you intend to upload the necessary files.\n",
        "\n"
      ],
      "metadata": {
        "id": "DWurH7TnDL2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    print(f'device: {device}')\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "\n",
        "dataMainDirectory = '/content/drive/MyDrive/ICIAP2023_SUBMISSION/'  #base path\n",
        "path_name = dataMainDirectory + '/' + 'VideoFolder'   #path to video folder\n",
        "testSet_folder_path = path_name\n",
        "\n",
        "fer67_cnn, incV3_cnn = importModels(dataMainDirectory)\n",
        "classification_model = classification_model_fc(dataMainDirectory)\n",
        "all_video_files = os.listdir(testSet_folder_path)\n",
        "testSet_name_list = [name_frame_num_Video(str(testSet_folder_path + '/' + vid)) for vid in all_video_files]\n",
        "print(testSet_name_list)\n",
        "testSet_df = pd.DataFrame(testSet_name_list, columns = ['filename','n_of_frames','fps'])\n",
        "testSet_df.set_index('filename', inplace=True)\n",
        "# METADATA\n",
        "testSet = testSet_df\n",
        "testSet.sort_index(inplace=True)\n",
        "min_N = min(testSet['n_of_frames'])\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "#import face_recognition\n",
        "print(f'IS DLIB USING CUDA? {dlib.DLIB_USE_CUDA}')\n",
        "#first N frames\n",
        "N = 300                 # changed next\n",
        "numeroDiVideo = len(testSet.index)\n",
        "print(numeroDiVideo)\n",
        "videoNonCaricati = 0\n",
        "i = 0\n",
        "video_start = 0\n",
        "test_video_path = path_name\n",
        "last_video_to_detect = 0\n",
        "tot_prediction= pd.DataFrame()\n",
        "\n",
        "face_detector_cnn = dlib.cnn_face_detection_model_v1(dataMainDirectory + '/' + 'mmod_human_face_detector.dat')\n",
        "log_df = pd.DataFrame(columns=['video_name','n_of_orginal_frames','detected_faces','n_interpolation','sample','frame_rate'])\n",
        "\n",
        "\n",
        "print(f'Video from {video_start} to {numeroDiVideo}')\n",
        "\n",
        "for nameVideo in all_video_files[video_start:numeroDiVideo]:\n",
        "  try:\n",
        "    since = time.time()\n",
        "    frame_rate = testSet.loc[nameVideo]['fps']\n",
        "    ast_video_to_detect = last_video_to_detect + 1\n",
        "    #gc.collect()\n",
        "    path_video_file = f'{test_video_path}/{nameVideo}'\n",
        "    print(f'\\n Reading: {path_video_file}')\n",
        "    frames_48 = []\n",
        "    frames_299 = []\n",
        "    frames_380_B3_convLSTM = []\n",
        "    ofVideo = []\n",
        "    frame_id = []\n",
        "    facesDetected = 0\n",
        "    facesInterpolated = 0\n",
        "    facesAugmented = 0\n",
        "    count = 0\n",
        "    first_frame = True    #TRACKING\n",
        "\n",
        "    # INTERPOLATION properties\n",
        "    bbox_last_detected_faces = []\n",
        "    index_detected = []\n",
        "    back_interp_frame_index = []\n",
        "    frames_back_interp = []\n",
        "    middle_interp_frame_index = []\n",
        "    frames_middle_interp = []\n",
        "    foreward_interp_frame_index = []\n",
        "    frames_forward_interp = []\n",
        "    frame_i = False\n",
        "    last_detected_frame_index = 0\n",
        "\n",
        "\n",
        "    N_OF_FRAMES = int(testSet.loc[nameVideo]['n_of_frames'])\n",
        "    N = N_OF_FRAMES\n",
        "    cap = cv2.VideoCapture(path_video_file)\n",
        "    while count < N:\n",
        "      resizedFrame = []\n",
        "      success, frame = cap.read()\n",
        "      count = count + 1\n",
        "      if success==True:\n",
        "        ofVideo.append(nameVideo)\n",
        "        frame_FSHS = increseContrast(frame)\n",
        "        grayContrast = cv2.cvtColor(frame_FSHS, cv2.COLOR_BGR2GRAY)\n",
        "        detected_faces_raw = face_detector_cnn(grayContrast, 1)\n",
        "\n",
        "        if len(detected_faces_raw) > 0:\n",
        "          last_detected_frame_index = count\n",
        "          if frame_i == False:\n",
        "            frame_i = True\n",
        "            resizeAndAppend()\n",
        "          else:\n",
        "            checkInterpolationAndResize()\n",
        "        else:\n",
        "          brightPlus_frame = increaseBrightnessBrg(frame)\n",
        "          moreContrastFrame = increseContrast(brightPlus_frame)\n",
        "          grayContrast = cv2.cvtColor(moreContrastFrame, cv2.COLOR_BGR2GRAY)\n",
        "          detected_faces_raw = face_detector_cnn(grayContrast, 1)\n",
        "          if len(detected_faces_raw) > 0:\n",
        "              last_detected_frame_index = count\n",
        "              if frame_i == False:\n",
        "                  frame_i = True\n",
        "                  resizeAndAppend()\n",
        "              else:\n",
        "                  checkInterpolationAndResize()\n",
        "          else:\n",
        "              autom_brigh_contr_frame = automaticBrightnessContrastBrg(frame)\n",
        "              detected_faces_raw = face_detector_cnn(autom_brigh_contr_frame, 1)\n",
        "              if len(detected_faces_raw) > 0:\n",
        "                  last_detected_frame_index = count\n",
        "                  if frame_i == False:\n",
        "                      frame_i = True\n",
        "                      resizeAndAppend()\n",
        "                  else:\n",
        "                      checkInterpolationAndResize()\n",
        "              else:\n",
        "                  autom_brigh_contr_frame = automaticBrightnessContrastBrg(frame)\n",
        "                  grayContrast_brigh = cv2.cvtColor(autom_brigh_contr_frame, cv2.COLOR_BGR2GRAY)\n",
        "                  detected_faces_raw = face_detector_cnn(grayContrast_brigh, 1)\n",
        "                  if len(detected_faces_raw) > 0:\n",
        "                      last_detected_frame_index = count\n",
        "                      if frame_i == False:\n",
        "                          frame_i = True\n",
        "                          resizeAndAppend()\n",
        "                      else:\n",
        "                          checkInterpolationAndResize()\n",
        "                  else:\n",
        "\n",
        "                      if facesDetected == 0:\n",
        "                          back_interp_frame_index.append(count)\n",
        "                          frames_back_interp.append(frame)\n",
        "                      else:\n",
        "                          middle_interp_frame_index.append(count)\n",
        "                          frames_middle_interp.append(frame)\n",
        "\n",
        "    if last_detected_frame_index == N or last_detected_frame_index == N_OF_FRAMES:\n",
        "      a = 1\n",
        "    else:\n",
        "      if not last_detected_frame_index == 0:\n",
        "        forwardInterpolation()\n",
        "      else:\n",
        "        print('error during cv2.read...')\n",
        "    cap.release()\n",
        "\n",
        "    ofVideo = [nameVideo] * (facesDetected + facesInterpolated)\n",
        "    all_frames_id = []\n",
        "    last_frame_id_list = frame_id\n",
        "    all_frames_id.extend(last_frame_id_list)\n",
        "    data_48 = np.array(frames_48)\n",
        "    reversed_data_48 = data_48[::-1]\n",
        "    data_299 = np.array(frames_299)\n",
        "    reversed_data_299 = data_299[::-1]\n",
        "\n",
        "    if not last_detected_frame_index == 0:\n",
        "      all300_frames_48 = data_48\n",
        "      all300_frames_299 = data_299\n",
        "      i = i + 1\n",
        "\n",
        "      #-------------------------------------------------------------------------------------------------- STEP 2\n",
        "      print('FEATURES EXTRACTION')\n",
        "      print(all300_frames_48.shape)\n",
        "      print(all300_frames_299.shape)\n",
        "      merged_df_fer67_IncV3 = features_extraction_step2(all300_frames_48, all300_frames_299, fer67_cnn, incV3_cnn )\n",
        "\n",
        "      #-------------------------------------------------------------------------------------------------- STEP 3\n",
        "      print('CLASSIFICATION')\n",
        "      n_rows = 300\n",
        "\n",
        "      x = [ element for element in merged_df_fer67_IncV3.columns if (element.startswith('f_I') or element.startswith('f_F'))]\n",
        "      merged_df_fer67_IncV3 = merged_df_fer67_IncV3[x]\n",
        "\n",
        "      if merged_df_fer67_IncV3.isnull().sum().sum() > 0:\n",
        "        print('problem with nan')\n",
        "        merged_df_fer67_IncV3 = merged_df_fer67_IncV3.fillna(method = 'ffill')\n",
        "\n",
        "      merged_df_fer67_IncV3 = merged_df_fer67_IncV3.values\n",
        "\n",
        "      if merged_df_fer67_IncV3.shape[0]>= n_rows:\n",
        "        data_to_predict = merged_df_fer67_IncV3[0:n_rows,:]\n",
        "      else:\n",
        "        data_to_predict = np.zeros((n_rows, merged_df_fer67_IncV3.shape[1]))\n",
        "        dim_real = merged_df_fer67_IncV3.shape[0]\n",
        "        reverse = merged_df_fer67_IncV3[::-1,:]\n",
        "        data_to_predict[:dim_real,:] = merged_df_fer67_IncV3\n",
        "        size_app = dim_real\n",
        "\n",
        "        while  dim_real< n_rows:\n",
        "          if n_rows> dim_real+size_app:\n",
        "            data_to_predict[dim_real: (dim_real+size_app),:] = reverse\n",
        "            reverse = reverse[::-1,:]\n",
        "            dim_real = (dim_real+size_app)\n",
        "          else:\n",
        "            data_to_predict[dim_real:,:] = reverse[0: (n_rows - dim_real)]\n",
        "            dim_real = n_rows\n",
        "\n",
        "      p = classification_model.predict(data_to_predict[np.newaxis,:,:])\n",
        "\n",
        "      print(f'          PREDICTION  {p} ')\n",
        "      time_elapsed = time.time()-since\n",
        "      data = {'video_name': nameVideo, 'prediction': p[0], 'time': time_elapsed}\n",
        "      tot_prediction = pd.concat((tot_prediction, pd.DataFrame( data = data, index=[0])), ignore_index=True)\n",
        "    else:\n",
        "      videoNonCaricati = videoNonCaricati + 1\n",
        "      time_elapsed = time.time()-since\n",
        "      data = {'video_name': nameVideo, 'prediction': np.nan, 'time': time_elapsed}\n",
        "      tot_prediction = pd.concat((tot_prediction, pd.DataFrame( data = data, index=[0])), ignore_index=True)\n",
        "\n",
        "  except:\n",
        "    videoNonCaricati = videoNonCaricati + 1\n",
        "    time_elapsed = time.time()-since\n",
        "    data = {'video_name': nameVideo, 'prediction': np.nan, 'time': time_elapsed}\n",
        "    tot_prediction = pd.concat((tot_prediction, pd.DataFrame( data = data, index=[0])), ignore_index=True)\n",
        "\n",
        "    print('[TIME: %.0f m %.0f s]'  %(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "#tot_prediction.to_csv(dataMainDirectory + 'Results_prediction.csv', index=False)\n",
        "print(tot_prediction)"
      ],
      "metadata": {
        "id": "tM5UJ73eCiF_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}